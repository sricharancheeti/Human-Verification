{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Multimodal Verification Model\n",
    "\n",
    "This is the entry point of the project. All the data processing modules are called in these module. Model is being trained in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "minMWXytkKEb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wave\n",
    "import pylab\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Add, Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D , Dropout , Concatenate, Reshape , Lambda\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Bidirectional,LSTM,Reshape\n",
    "from keras.models import Model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.metrics import Recall,Precision\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxyAETHZilb4",
    "outputId": "ebd13593-0935-49b3-bc9c-1330daf99526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JfVvG6PCJ34"
   },
   "outputs": [],
   "source": [
    "import extract_data\n",
    "import create_multimodal_pairs\n",
    "import architectures\n",
    "import siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUWqwdMTfjk-"
   },
   "outputs": [],
   "source": [
    "# Declare constants\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 20\n",
    "\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "IMG_SHAPE = (IMAGE_HEIGHT,IMAGE_WIDTH,N_CHANNELS)\n",
    "\n",
    "AUD_HEIGHT = 128\n",
    "AUD_WIDTH = 128\n",
    "AUD_SHAPE = (AUD_HEIGHT,AUD_WIDTH,N_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from the data directory using the extract_data.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYZbSHvsECPR"
   },
   "outputs": [],
   "source": [
    "data_dir =  #set path to the folder containing subfolders containing your images \n",
    "\n",
    "#list of subfolders which denote different classes of your dataset\n",
    "categories = os.listdir(data_dir)\n",
    "\n",
    "data_img = []\n",
    "categorical_index_img = [] #to keep track of which class is mapped to which index\n",
    "\n",
    "data_img,categorical_index_img = extract_data.create_data(data_dir,categories,data_img,categorical_index_img,IMAGE_HEIGHT,IMAGE_WIDTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wZend0cEJJC"
   },
   "outputs": [],
   "source": [
    "data_dir =#set path to the folder containing subfolders containing the audio spectogram images\n",
    "\n",
    "#list of subfolders which denote different classes of your dataset\n",
    "categories = os.listdir(data_dir)\n",
    "\n",
    "data_aud = []\n",
    "categorical_index_aud = []\n",
    "\n",
    "data_aud,categorical_index_aud = extract_data.create_data(data_dir,categories,data_aud,categorical_index_aud,AUD_HEIGHT,AUD_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomizing the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWKj8oFAFgwb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(33)\n",
    "random.shuffle(data_img)\n",
    "random.shuffle(data_aud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwgu3M4QEgpN"
   },
   "outputs": [],
   "source": [
    "# creating X and y from data list\n",
    "\n",
    "X_img,y_img = extract_data.extract_features_and_labels(data_img)\n",
    "X_aud,y_aud = extract_data.extract_features_and_labels(data_aud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sa0ZAFjJQlo",
    "outputId": "41338738-c07d-46d6-aac5-5e36ae9db61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:(587, 128, 128, 3)\n",
      "Shape of y_train:(587,)\n",
      "Shape of X_test:(66, 128, 128, 3)\n",
      "Shape of y_test:(66,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# segregating the training and test image data\n",
    "X_train_img,X_test_img,y_train_img,y_test_img = train_test_split(X_img,y_img,test_size=0.1) # 0.1 test to train split \n",
    "\n",
    "# segregating the training and test audio data\n",
    "X_train_aud,X_test_aud,y_train_aud,y_test_aud = train_test_split(X_aud,y_aud,test_size=0.1) # 0.1 test to train split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forming the data pairs of image and audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6F9lvaMIQwc"
   },
   "outputs": [],
   "source": [
    "# create pairs from training data\n",
    "\n",
    "# to define the same list of classes\n",
    "same_class_list1 = []\n",
    "same_class_list2 = []\n",
    "img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train  = create_multimodal_pairs.multimodal_data_generate(X_train_img , y_train_img , X_train_aud , y_train_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Clxwdz9cIZuT"
   },
   "outputs": [],
   "source": [
    "# create pairs from test data\n",
    "\n",
    "# to define the same list of classes\n",
    "same_class_list1 = []\n",
    "same_class_list2 = [] \n",
    "img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test  = create_multimodal_pairs.multimodal_data_generate(X_test_img , y_test_img , X_test_aud , y_test_aud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize the data pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2m7ZwNw_PDD"
   },
   "outputs": [],
   "source": [
    "# randomize the train data\n",
    "\n",
    "img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train = extract_data.randomize_zip(img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nlcaR6GPrzY"
   },
   "outputs": [],
   "source": [
    "# randomize the test data\n",
    "\n",
    "img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test = extract_data.randomize_zip(img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdlH9rVNDdrm"
   },
   "outputs": [],
   "source": [
    "input_dim_img = (IMAGE_HEIGHT,IMAGE_WIDTH,N_CHANNELS)\n",
    "input_dim_aud = (AUD_HEIGHT,AUD_WIDTH,N_CHANNELS)\n",
    "\n",
    "# final model train \n",
    "optimizer , model = siamese.siamese_network(input_dim_img , input_dim_aud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5kt9Rj8AQuh"
   },
   "outputs": [],
   "source": [
    "weight_dir = #set a weights directory\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.mkdir(weight_dir)\n",
    "    \n",
    "#checkpoints for best weights in terms of validation accuracy\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=weight_dir+'/checkpoint-{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIB-NYoRlVLh"
   },
   "outputs": [],
   "source": [
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "model.fit([np.asarray(img_a_train),np.asarray(aud_a_train),np.asarray(img_b_train),np.asarray(aud_b_train)], np.asarray(labels_train) ,validation_split=0.2, batch_size = BATCH_SIZE , verbose = 1, epochs = 30 , callbacks = checkpoint)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "execute_multimodal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
